{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6422a19e",
   "metadata": {},
   "source": [
    "### Project Description\n",
    "\n",
    "We have the data of IMDB movie reviews labelled as positive or negative. For each sentiment positive and negative we have 12500 data points for each. The goal of this project is to classify the reviews as positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01738cd",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f1b2ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  I thought this was a wonderful way to spend ti...  positive\n",
       "1  Probably my all-time favorite movie, a story o...  positive\n",
       "2  I sure would like to see a resurrection of a u...  positive\n",
       "3  This show was an amazing, fresh & innovative i...  negative\n",
       "4  Encouraged by the positive comments about this...  negative"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('IMDB_review.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc3537ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b73f0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    12500\n",
       "positive    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d27efbd",
   "metadata": {},
   "source": [
    "#### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "742ee605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8fef305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_nopunct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Probably my alltime favorite movie a story of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>This show was an amazing fresh  innovative ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  I thought this was a wonderful way to spend ti...  positive   \n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  Encouraged by the positive comments about this...  negative   \n",
       "\n",
       "                                      review_nopunct  \n",
       "0  I thought this was a wonderful way to spend ti...  \n",
       "1  Probably my alltime favorite movie a story of ...  \n",
       "2  I sure would like to see a resurrection of a u...  \n",
       "3  This show was an amazing fresh  innovative ide...  \n",
       "4  Encouraged by the positive comments about this...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct\n",
    "\n",
    "data['review_nopunct'] = data['review'].apply(lambda x : remove_punct(x))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773858a9",
   "metadata": {},
   "source": [
    "Added a new column without the punctuation marks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e05a9",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf20c720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_nopunct</th>\n",
       "      <th>review_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>[i, thought, this, was, a, wonderful, way, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Probably my alltime favorite movie a story of ...</td>\n",
       "      <td>[probably, my, alltime, favorite, movie, a, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>[i, sure, would, like, to, see, a, resurrectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>This show was an amazing fresh  innovative ide...</td>\n",
       "      <td>[this, show, was, an, amazing, fresh, innovati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>[encouraged, by, the, positive, comments, abou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  I thought this was a wonderful way to spend ti...  positive   \n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  Encouraged by the positive comments about this...  negative   \n",
       "\n",
       "                                      review_nopunct  \\\n",
       "0  I thought this was a wonderful way to spend ti...   \n",
       "1  Probably my alltime favorite movie a story of ...   \n",
       "2  I sure would like to see a resurrection of a u...   \n",
       "3  This show was an amazing fresh  innovative ide...   \n",
       "4  Encouraged by the positive comments about this...   \n",
       "\n",
       "                                       review_tokens  \n",
       "0  [i, thought, this, was, a, wonderful, way, to,...  \n",
       "1  [probably, my, alltime, favorite, movie, a, st...  \n",
       "2  [i, sure, would, like, to, see, a, resurrectio...  \n",
       "3  [this, show, was, an, amazing, fresh, innovati...  \n",
       "4  [encouraged, by, the, positive, comments, abou...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+',text)\n",
    "    return tokens\n",
    "\n",
    "data['review_tokens'] = data['review_nopunct'].apply(lambda x: tokenize(x.lower()))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53969e0",
   "metadata": {},
   "source": [
    "Created the word tokens from the column which was added in previous step without punctuation marks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467b1bb8",
   "metadata": {},
   "source": [
    "#### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d45d3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2eae892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_nopunct</th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>review_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>[i, thought, this, was, a, wonderful, way, to,...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Probably my alltime favorite movie a story of ...</td>\n",
       "      <td>[probably, my, alltime, favorite, movie, a, st...</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>[i, sure, would, like, to, see, a, resurrectio...</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>This show was an amazing fresh  innovative ide...</td>\n",
       "      <td>[this, show, was, an, amazing, fresh, innovati...</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70s, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>[encouraged, by, the, positive, comments, abou...</td>\n",
       "      <td>[encouraged, positive, comments, film, looking...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  I thought this was a wonderful way to spend ti...  positive   \n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  Encouraged by the positive comments about this...  negative   \n",
       "\n",
       "                                      review_nopunct  \\\n",
       "0  I thought this was a wonderful way to spend ti...   \n",
       "1  Probably my alltime favorite movie a story of ...   \n",
       "2  I sure would like to see a resurrection of a u...   \n",
       "3  This show was an amazing fresh  innovative ide...   \n",
       "4  Encouraged by the positive comments about this...   \n",
       "\n",
       "                                       review_tokens  \\\n",
       "0  [i, thought, this, was, a, wonderful, way, to,...   \n",
       "1  [probably, my, alltime, favorite, movie, a, st...   \n",
       "2  [i, sure, would, like, to, see, a, resurrectio...   \n",
       "3  [this, show, was, an, amazing, fresh, innovati...   \n",
       "4  [encouraged, by, the, positive, comments, abou...   \n",
       "\n",
       "                                       review_nostop  \n",
       "0  [thought, wonderful, way, spend, time, hot, su...  \n",
       "1  [probably, alltime, favorite, movie, story, se...  \n",
       "2  [sure, would, like, see, resurrection, dated, ...  \n",
       "3  [show, amazing, fresh, innovative, idea, 70s, ...  \n",
       "4  [encouraged, positive, comments, film, looking...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopword(token_list):\n",
    "    text = [word for word in token_list if word not in stopword]\n",
    "    return text\n",
    "\n",
    "data['review_nostop'] = data['review_tokens'].apply(lambda x: remove_stopword(x))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b7554c",
   "metadata": {},
   "source": [
    "From the tokens created removed the stopwords and added the column in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f7e568",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d85034",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07858e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_nopunct</th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>review_nostop</th>\n",
       "      <th>review_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>[i, thought, this, was, a, wonderful, way, to,...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[thought, wonder, way, spend, time, hot, summe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Probably my alltime favorite movie a story of ...</td>\n",
       "      <td>[probably, my, alltime, favorite, movie, a, st...</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, se...</td>\n",
       "      <td>[probabl, alltim, favorit, movi, stori, selfle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>[i, sure, would, like, to, see, a, resurrectio...</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, ...</td>\n",
       "      <td>[sure, would, like, see, resurrect, date, seah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>This show was an amazing fresh  innovative ide...</td>\n",
       "      <td>[this, show, was, an, amazing, fresh, innovati...</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70s, ...</td>\n",
       "      <td>[show, amaz, fresh, innov, idea, 70, first, ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>[encouraged, by, the, positive, comments, abou...</td>\n",
       "      <td>[encouraged, positive, comments, film, looking...</td>\n",
       "      <td>[encourag, posit, comment, film, look, forward...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  I thought this was a wonderful way to spend ti...  positive   \n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  Encouraged by the positive comments about this...  negative   \n",
       "\n",
       "                                      review_nopunct  \\\n",
       "0  I thought this was a wonderful way to spend ti...   \n",
       "1  Probably my alltime favorite movie a story of ...   \n",
       "2  I sure would like to see a resurrection of a u...   \n",
       "3  This show was an amazing fresh  innovative ide...   \n",
       "4  Encouraged by the positive comments about this...   \n",
       "\n",
       "                                       review_tokens  \\\n",
       "0  [i, thought, this, was, a, wonderful, way, to,...   \n",
       "1  [probably, my, alltime, favorite, movie, a, st...   \n",
       "2  [i, sure, would, like, to, see, a, resurrectio...   \n",
       "3  [this, show, was, an, amazing, fresh, innovati...   \n",
       "4  [encouraged, by, the, positive, comments, abou...   \n",
       "\n",
       "                                       review_nostop  \\\n",
       "0  [thought, wonderful, way, spend, time, hot, su...   \n",
       "1  [probably, alltime, favorite, movie, story, se...   \n",
       "2  [sure, would, like, see, resurrection, dated, ...   \n",
       "3  [show, amazing, fresh, innovative, idea, 70s, ...   \n",
       "4  [encouraged, positive, comments, film, looking...   \n",
       "\n",
       "                                         review_stem  \n",
       "0  [thought, wonder, way, spend, time, hot, summe...  \n",
       "1  [probabl, alltim, favorit, movi, stori, selfle...  \n",
       "2  [sure, would, like, see, resurrect, date, seah...  \n",
       "3  [show, amaz, fresh, innov, idea, 70, first, ai...  \n",
       "4  [encourag, posit, comment, film, look, forward...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stemming(tokenized_text):\n",
    "    word_stem = [ps.stem(word) for word in tokenized_text]\n",
    "    return word_stem\n",
    "\n",
    "data['review_stem'] = data['review_nostop'].apply(lambda x: stemming(x))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1682168",
   "metadata": {},
   "source": [
    "Word stems are created and added in the data as new column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f00c272",
   "metadata": {},
   "source": [
    "#### Lemmatize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "861e5da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ccec4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dhamn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb49a52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_nopunct</th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>review_nostop</th>\n",
       "      <th>review_stem</th>\n",
       "      <th>review_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>[i, thought, this, was, a, wonderful, way, to,...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[thought, wonder, way, spend, time, hot, summe...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Probably my alltime favorite movie a story of ...</td>\n",
       "      <td>[probably, my, alltime, favorite, movie, a, st...</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, se...</td>\n",
       "      <td>[probabl, alltim, favorit, movi, stori, selfle...</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>[i, sure, would, like, to, see, a, resurrectio...</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, ...</td>\n",
       "      <td>[sure, would, like, see, resurrect, date, seah...</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>This show was an amazing fresh  innovative ide...</td>\n",
       "      <td>[this, show, was, an, amazing, fresh, innovati...</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70s, ...</td>\n",
       "      <td>[show, amaz, fresh, innov, idea, 70, first, ai...</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>[encouraged, by, the, positive, comments, abou...</td>\n",
       "      <td>[encouraged, positive, comments, film, looking...</td>\n",
       "      <td>[encourag, posit, comment, film, look, forward...</td>\n",
       "      <td>[encouraged, positive, comment, film, looking,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  I thought this was a wonderful way to spend ti...  positive   \n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  Encouraged by the positive comments about this...  negative   \n",
       "\n",
       "                                      review_nopunct  \\\n",
       "0  I thought this was a wonderful way to spend ti...   \n",
       "1  Probably my alltime favorite movie a story of ...   \n",
       "2  I sure would like to see a resurrection of a u...   \n",
       "3  This show was an amazing fresh  innovative ide...   \n",
       "4  Encouraged by the positive comments about this...   \n",
       "\n",
       "                                       review_tokens  \\\n",
       "0  [i, thought, this, was, a, wonderful, way, to,...   \n",
       "1  [probably, my, alltime, favorite, movie, a, st...   \n",
       "2  [i, sure, would, like, to, see, a, resurrectio...   \n",
       "3  [this, show, was, an, amazing, fresh, innovati...   \n",
       "4  [encouraged, by, the, positive, comments, abou...   \n",
       "\n",
       "                                       review_nostop  \\\n",
       "0  [thought, wonderful, way, spend, time, hot, su...   \n",
       "1  [probably, alltime, favorite, movie, story, se...   \n",
       "2  [sure, would, like, see, resurrection, dated, ...   \n",
       "3  [show, amazing, fresh, innovative, idea, 70s, ...   \n",
       "4  [encouraged, positive, comments, film, looking...   \n",
       "\n",
       "                                         review_stem  \\\n",
       "0  [thought, wonder, way, spend, time, hot, summe...   \n",
       "1  [probabl, alltim, favorit, movi, stori, selfle...   \n",
       "2  [sure, would, like, see, resurrect, date, seah...   \n",
       "3  [show, amaz, fresh, innov, idea, 70, first, ai...   \n",
       "4  [encourag, posit, comment, film, look, forward...   \n",
       "\n",
       "                                        review_lemma  \n",
       "0  [thought, wonderful, way, spend, time, hot, su...  \n",
       "1  [probably, alltime, favorite, movie, story, se...  \n",
       "2  [sure, would, like, see, resurrection, dated, ...  \n",
       "3  [show, amazing, fresh, innovative, idea, 70, f...  \n",
       "4  [encouraged, positive, comment, film, looking,...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize(tokenized_text):\n",
    "    word_lemma = [ wn.lemmatize(word) for word in tokenized_text]\n",
    "    return word_lemma\n",
    "\n",
    "data['review_lemma'] = data['review_nostop'].apply(lambda x: lemmatize(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58638737",
   "metadata": {},
   "source": [
    "Lemmatization modifies the word to its root word, the words are lemmatized and added as new column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28673499",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8692fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create function to remove punctuation, tokenize, remove stopwords, and stem\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0df3af25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 93696)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer = clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['review'])\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29085979",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_df = pd.DataFrame(X_tfidf.toarray())\n",
    "X_tfidf_df.columns = tfidf_vect.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f1f552",
   "metadata": {},
   "source": [
    "Here we have created the TF-IDF word vectors for different words in the text and converted them as feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07ad882",
   "metadata": {},
   "source": [
    "### Build RF with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "758d03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79a580c",
   "metadata": {},
   "source": [
    "##### Tried using GridSearchCV function, but the issue was it was not allocating enough processing memory even for 6K records, tried reducing the records to 5K and 4K still same error.\n",
    "\n",
    "##### When tried using 3K records, still the model training was not completed after 15 mins, also 3K records are practically very less for model training as compared to the features.\n",
    "\n",
    "##### So here, I have opted for building own GridSearch method, as showcased in one of the lecture python notebooks which takes couple of seconds to train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d43a45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Taking the subset of data to train the model faster\n",
    "\n",
    "features = X_tfidf_df[0:6000]\n",
    "labels = data['sentiment'][0:6000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "577fc909",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adc027c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RF(n_est, depth):\n",
    "    rf = RandomForestClassifier(n_estimators=n_est, max_depth=depth, n_jobs=-1)\n",
    "    rf_model = rf.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label='positive', average='binary')\n",
    "    print('Est: {} / Depth: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "        n_est, depth, round(precision, 3), round(recall, 3),\n",
    "        round((y_pred==y_test).sum() / len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5f8fd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 10 / Depth: 10 ---- Precision: 0.728 / Recall: 0.715 / Accuracy: 0.718\n",
      "Est: 10 / Depth: 20 ---- Precision: 0.71 / Recall: 0.712 / Accuracy: 0.703\n",
      "Est: 10 / Depth: 30 ---- Precision: 0.765 / Recall: 0.724 / Accuracy: 0.744\n",
      "Est: 10 / Depth: None ---- Precision: 0.734 / Recall: 0.634 / Accuracy: 0.695\n",
      "Est: 50 / Depth: 10 ---- Precision: 0.834 / Recall: 0.725 / Accuracy: 0.785\n",
      "Est: 50 / Depth: 20 ---- Precision: 0.807 / Recall: 0.81 / Accuracy: 0.803\n",
      "Est: 50 / Depth: 30 ---- Precision: 0.835 / Recall: 0.767 / Accuracy: 0.803\n",
      "Est: 50 / Depth: None ---- Precision: 0.852 / Recall: 0.798 / Accuracy: 0.826\n",
      "Est: 100 / Depth: 10 ---- Precision: 0.848 / Recall: 0.774 / Accuracy: 0.813\n",
      "Est: 100 / Depth: 20 ---- Precision: 0.853 / Recall: 0.833 / Accuracy: 0.841\n",
      "Est: 100 / Depth: 30 ---- Precision: 0.834 / Recall: 0.785 / Accuracy: 0.81\n",
      "Est: 100 / Depth: None ---- Precision: 0.842 / Recall: 0.797 / Accuracy: 0.819\n"
     ]
    }
   ],
   "source": [
    "for n_est in [10, 50, 100]:\n",
    "    for depth in [10, 20, 30, None]:\n",
    "        train_RF(n_est, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2babbff5",
   "metadata": {},
   "source": [
    "We can see that the RF model performed well at predictions when trained for **`n_estimators:100`** and **`max_depth:20`**. The accuracy of the the model is around 84% and the precision and recall scores are also quite well. So we choose these parameters for our final model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734443d8",
   "metadata": {},
   "source": [
    "#### Evaluate model on best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d465f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "388942e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 31.017 / Predict time: 2.669 ---- Precision: 0.844 / Recall: 0.793 / Accuracy: 0.819\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=20, n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "rf_model = rf.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "start = time.time()\n",
    "y_pred = rf_model.predict(X_test)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label='positive', average='binary')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46186c5",
   "metadata": {},
   "source": [
    "The model fit time was around 20.48 sec and the time taken to predict was 0.985 sec, here also the accuracy, precision and recall scores seem to be pretty well, we can say that overall the model performs good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79b6332",
   "metadata": {},
   "source": [
    "### Build Gradient Boosting with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea725981",
   "metadata": {},
   "outputs": [],
   "source": [
    "##from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7946003",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_new = labels.map({'positive': 1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22708668",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_new, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b772e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GB(est, max_depth):\n",
    "    gb = XGBClassifier(n_estimators=est, max_depth=max_depth)\n",
    "    gb_model = gb.fit(X_train, y_train)\n",
    "    y_pred = gb_model.predict(X_test)\n",
    "    precision, recall, fscore, train_support = score(y_test, y_pred, pos_label= 1, average='binary')\n",
    "    print('Est: {} / Depth: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "        est, max_depth, round(precision, 3), round(recall, 3), \n",
    "        round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49ec7d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 10 / Depth: 10 ---- Precision: 0.77 / Recall: 0.816 / Accuracy: 0.785\n",
      "Est: 10 / Depth: 20 ---- Precision: 0.784 / Recall: 0.8 / Accuracy: 0.788\n",
      "Est: 10 / Depth: 30 ---- Precision: 0.783 / Recall: 0.793 / Accuracy: 0.785\n",
      "Est: 10 / Depth: None ---- Precision: 0.76 / Recall: 0.833 / Accuracy: 0.783\n",
      "Est: 50 / Depth: 10 ---- Precision: 0.826 / Recall: 0.858 / Accuracy: 0.838\n",
      "Est: 50 / Depth: 20 ---- Precision: 0.828 / Recall: 0.839 / Accuracy: 0.832\n",
      "Est: 50 / Depth: 30 ---- Precision: 0.815 / Recall: 0.829 / Accuracy: 0.819\n",
      "Est: 50 / Depth: None ---- Precision: 0.818 / Recall: 0.856 / Accuracy: 0.832\n",
      "Est: 100 / Depth: 10 ---- Precision: 0.843 / Recall: 0.863 / Accuracy: 0.85\n",
      "Est: 100 / Depth: 20 ---- Precision: 0.843 / Recall: 0.854 / Accuracy: 0.847\n",
      "Est: 100 / Depth: 30 ---- Precision: 0.829 / Recall: 0.836 / Accuracy: 0.831\n",
      "Est: 100 / Depth: None ---- Precision: 0.851 / Recall: 0.871 / Accuracy: 0.858\n"
     ]
    }
   ],
   "source": [
    "for n_est in [10, 50, 100]:\n",
    "    for depth in [10, 20, 30, None]:\n",
    "        train_GB(n_est, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a527432c",
   "metadata": {},
   "source": [
    "In XGBoost algorithm we got an accuracy of around 85.8% with **`n_estimators:100`** and **`Depth:None`**. We will evaluate our model using these parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc301a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 1026.563 / Predict time: 9.086 ---- Precision: 0.851 / Recall: 0.871 / Accuracy: 0.858\n"
     ]
    }
   ],
   "source": [
    "gb = XGBClassifier(n_estimators=100, max_depth=None)\n",
    "\n",
    "start = time.time()\n",
    "gb_model = gb.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "start = time.time()\n",
    "y_pred = gb_model.predict(X_test)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label=1, average='binary')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b17a92",
   "metadata": {},
   "source": [
    "We can see that the training time is huge which is approximately **20 mins** and predict time is 9 secs. The accuracy is around 85% and precision recall values are pretty well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e8cc5",
   "metadata": {},
   "source": [
    "- Overall if we see RF and XGBoost, the accuracy difference is less as compared to the huge training time and memory occupied by XGBoost. We would choose a model which gives decent accuracy as well as trains faster.\n",
    "\n",
    "- So we can say that RF out performs XGBoost in this matter, as accuaracy is decent and precision, recall values are also good.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
